hive> CREATE TABLE flight_info_staging(
> FL_NUM INT,
> ORIGIN_AIRPORT_ID INT,
> ORIGIN STRING,
> DEST_AIRPORT_ID INT,
> DEST STRING,
> DEP_TIME INT,
> DEP_DELAY INT,
> ARR_TIME INT,
> ARR_DELAY INT
>)
> ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
> tblproperties ("skip.header.line.count"="1");
OK
Time taken: 0.143 seconds
hive> LOAD DATA LOCAL INPATH
> '/home/akansha/flightdata.csv'
> INTO TABLE flight_info_staging;
Loading data to table flight_info_system.flight_info_staging
OK
Time taken: 0.58 seconds

hive> CREATE TABLE flight_info (
> FL_NUM INT,
> ORIGIN_AIRPORT_ID INT,
> ORIGIN STRING,
> DEST_AIRPORT_ID INT,
> DEST STRING,
> DEP_TIME INT,
> DEP_DELAY INT,
> ARR_TIME INT,
> ARR_DELAY INT
>)
> STORED AS ORC;
OK
Time taken: 0.091 seconds
hive> INSERT INTO TABLE flight_info SELECT * FROM flight_info_staging;
Query ID = akansha_20230528050857_b88265d4-fe0c-49b0-ac8e-c0f7d23ab222
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
set hive.exec.reducers.max=<number>

In order to set a constant number of reducers:
set mapreduce.job.reduces=<number>
Starting Job = job_1685219240726_0010, Tracking URL =
http://akansha-VirtualBox:8088/proxy/application_1685219240726_0010/
Kill Command = /home/akansha/hadoop-3.2.4/bin/mapred job -kill
job_1685219240726_0010
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2023-05-28 05:09:09,638 Stage-1 map = 0%, reduce = 0%
2023-05-28 05:09:14,938 Stage-1 map = 100%, reduce = 0%, Cumulative CPU 3.71 sec
2023-05-28 05:09:20,188 Stage-1 map = 100%, reduce = 100%, Cumulative CPU 5.25 sec
MapReduce Total cumulative CPU time: 5 seconds 250 msec
Ended Job = job_1685219240726_0010
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to directory
hdfs://localhost:9000/user/hive/warehouse/flight_info_system.db/flight_info/.hive-staging_hiv
e_2023-05-28_05-08-57_810_2189922168505621243-1/-ext-10000
Loading data to table flight_info_system.flight_info
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1 Reduce: 1 Cumulative CPU: 5.25 sec HDFS Read: 496804 HDFS
Write: 70534 SUCCESS
Total MapReduce CPU Time Spent: 5 seconds 250 msec
OK
Time taken: 24.157 seconds
hive> DROP TABLE flight_info_staging;
OK
Time taken: 0.192 seconds
hive>
hive> select count(*) from flight_info;
OK
11231
Time taken: 0.541 seconds, Fetched: 1 row(s)
hive>
hive> CREATE INDEX idx_dep_delay ON TABLE flight_info (DEP_DELAY);
NoViableAltException(152@[917:1: ddlStatement : ( createDatabaseStatement |
switchDatabaseStatement | dropDatabaseStatement | createTableStatement |
dropTableStatement | truncateTableStatement | alterStatement | descStatement |
showStatement | metastoreCheck | createViewStatement | createMaterializedViewStatement
| dropViewStatement | dropMaterializedViewStatement | createFunctionStatement |
createMacroStatement | dropFunctionStatement | reloadFunctionStatement |
dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase |
unlockDatabase | createRoleStatement | dropRoleStatement | ( grantPrivileges )=>
grantPrivileges | ( revokePrivileges )=> revokePrivileges | showGrants | showRoleGrants |
showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole |
abortTransactionStatement | killQueryStatement | resourcePlanDdlStatements );])

at org.antlr.runtime.DFA.noViableAlt(DFA.java:158)
at org.antlr.runtime.DFA.predict(DFA.java:116)
at org.apache.hadoop.hive.ql.parse.HiveParser.ddlStatement(HiveParser.java:4244)
at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:2494)
at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1420)
at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:220)
at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:74)
at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:67)
at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:616)
at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1826)
at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1773)
at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1768)
at
org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:12
6)
at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:214)
at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:239)
at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:188)
at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:402)
at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:821)
at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:759)
at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:683)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
FAILED: ParseException line 1:7 cannot recognize input near 'CREATE' 'INDEX'
'idx_dep_delay' in ddl statement
hive>
hive> CREATE INDEX idx_dep_delay ON TABLE flight_info (DEP_DELAY) AS
'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler';
NoViableAltException(152@[917:1: ddlStatement : ( createDatabaseStatement |
switchDatabaseStatement | dropDatabaseStatement | createTableStatement |
dropTableStatement | truncateTableStatement | alterStatement | descStatement |
showStatement | metastoreCheck | createViewStatement | createMaterializedViewStatement
| dropViewStatement | dropMaterializedViewStatement | createFunctionStatement |
createMacroStatement | dropFunctionStatement | reloadFunctionStatement |
dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase |
unlockDatabase | createRoleStatement | dropRoleStatement | ( grantPrivileges )=>
grantPrivileges | ( revokePrivileges )=> revokePrivileges | showGrants | showRoleGrants |
showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole |
abortTransactionStatement | killQueryStatement | resourcePlanDdlStatements );])
at org.antlr.runtime.DFA.noViableAlt(DFA.java:158)
at org.antlr.runtime.DFA.predict(DFA.java:116)

at org.apache.hadoop.hive.ql.parse.HiveParser.ddlStatement(HiveParser.java:4244)
at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:2494)
at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1420)
at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:220)
at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:74)
at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:67)
at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:616)
at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1826)
at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1773)
at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1768)
at
org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:12
6)
at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:214)
at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:239)
at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:188)
at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:402)
at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:821)
at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:759)
at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:683)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
FAILED: ParseException line 1:7 cannot recognize input near 'CREATE' 'INDEX'
'idx_dep_delay' in ddl statement

